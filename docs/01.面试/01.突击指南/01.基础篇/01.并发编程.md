---
title: 并发编程
date: 2023-07-03 15:09:09
permalink: /pages/6ef0a4/
---

# 1.并发的三大特性

并发的三大特性包括：原子性、可见性、有序性

## 1.1.什么是原子性

原子性就是指一个操作是不可分割的，也是不可中断的，当我一个线程正在执行的时候，另外一个线程是不会影响到它的。

在java层面为了实现这种原子性有很多种保证方式

- 第一种就是synchronized互斥锁，如果说你想执行某一段指令或者执行某段代码，你必须要先持有我的synchronized锁才可以去执行，这样的话呢就做到了完全的互斥；线程a执行的时候，线程b等待我的a执行完，b才可以执行
- 第二种方式是CAS，这个CAS其实是java中一种乐观锁的实现，前面这边说到的synchronized，如果线程b没有拿到资源，那么他会挂起，这个时候涉及到用户态到内核态的转换，会消耗一些额外的资源。而CAS他是操作系统的CPU层面的的一个术语，它是在cpu层面保证的一个原子性，你的线程a在执行的时候，线程b是不可以执行的，但是这种方式的话，他没有带来用户态到内核态的转换，所以他会频繁的去操作CPU。java中的atomic这种原子类底层就是基于CAS实现的，他会带来CPU消耗过多的一个问题
- 第三种就是基于LOCK锁实现的，这个lock锁到道格里基于CAS+AQS实现的，他的底层是通过执行lock和unlock实现的，在lock的过程中，他会调用CAS和AQS这种排队的一个策略，所以他比synchronized效率高，但是在jdk1.6之后synchronized做了优化之后，他们的效率就差不多了

```java
private static int count;
private static ReentrantLock lock = new ReentrantLock();
public static void increment() { 
    lock.lock();
    try {
        count++; 
        try {                     
            Thread.sleep(10);                   
        } catch (InterruptedException e) {
            e.printStackTrace(); 
        }
    } finally { 
        lock.unlock();                             
    }
                               
}
```

- 第四种是ThreadLocal，虽然使用ThreadLocal很难保证原子性，但是我们要保证原子性的根本原因是避免共享变量带来的线程安全问题，那使用ThreadLocal的话，可以不让多线程去操作这种共享资源。让每个线程只去操作属于自己的数据。

## 1.2.什么是可见性

可见性问题是基于CPU位置出现的，CPU处理速度非常快，相对CPU来说，去主内存获取数据这个事情太慢了，CPU就提供了L1，L2，L3的三级缓存，每次去主内存拿完数据后，就会存储到CPU的三级缓存，每次去三级缓存拿数据，效率肯定会提升。 

这就带来了问题，现在CPU都是多核，每个线程的工作内存(CPU三级缓存)都是独立的，会导致每个线程中做修改时，只改自己的工作内存，没有及时的同步到主内存，导致数据不一致问题。 

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686293730242-61764655-73ac-4e7b-af14-9e461d26e18f.png)

为了保证可见性有很多种方式

- 第一种也是最彻底的方式就是给你的那个要保证可见性的变量加上voltail来修饰，如果属性被volatile修饰，相当于会告诉CPU，对当前属性的操作，不允许使用CPU的缓存，必须去和主内存操作。那么每次去读或者写的时候，就会直接将数据更新到主存当中
- 第二种方式就是使用synchronized，它在加锁的同时会将数据同步到主内存，但是它只在加锁的这一时刻生效，如果在内部做了一些事情，它依然是无法保证可见性的，但是在一定层面是可以解决的只不过没有volatile那么彻底
- 第三种方式就是基于lock的方式，lock保证原子性的方式与synchronized不同，synchronized是基于他的内存语义在获取锁和释放锁时，对CPU缓存做一个同步到主内存的操作。而lock锁的内部会基于CAS去操作一个volatile修饰的变量，他是基于咱们happens-before这种原则操作的，如果说你在前面操作了，那么后续对或者对一个volatile数据进行了写操作，那么他后续的操作也是可以保证可见性，它跟synchronize类似，只在执行那一刻会保证这种可见性
- 最后一种就是final，final修饰的变量都不能修改，那么自然不需要保证可见性了

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686294913446-1d2e291c-9fe1-4e06-a3ec-77bb777e9111.png)

## 1.3.什么是有序性

java在编译某一个.java文件的时候，j i t会对编译做一个优化，可能会指令重排，另一个就是cpu在执行指令的时候，他可能为了保证或者提升我的效率会对这种指令做一个重排

保证程序的有序性

- 第一种也是最核心的方式还是基于volatile，依然是在你的某一个指令的前后或者只在后面去追加不同的内存屏障，然后无论是store load还是load store这种东西最终都可以保证咱们的指令不会被重排
- 第二种是happens-before原则来保证或者避免指令重排

# 2.什么是CAS，有什么优缺点

CAS就是compare and swap也就是比较和交换，它可以保证原子性，是基于cpu层面去保证，而不是java层面；java在调用CAS的时候，一般是基于native方法去实现的，他里边有个unsafe类，这个类里边有compareAndSwap方法，有替换Object的方法、Int和Long的方法。这种CAS其实就是在替换内存中某一个位置的值时，先查看内存中的值是否与预期值是一致的，如果一致，我就执行替换操作；如果不一致，就不去执行这个替换，这种保证原子性的方式他并不会和synchronized一样让你的线程进入阻塞状态

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686298963135-857d44fa-0ef4-4d8d-af61-8ef08cd1992d.png)

在java8中的AtomicInteger中就用到了CAS，对某一个value进行加加操作时，会有一个do{}while循环，不停的调用compareAndSwapInt方法，只有调用成功了之后才会退出循环所以他的

- 优点就是线程不会挂起，避免了用户态到内核态的一个切换。
- 缺点就是如果并发量比较大的话，执行cas失败，那么会一直进行cas，浪费cpu资源



![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686299366685-981170b6-24ef-4b20-a9a9-1d8cf29919f4.png)

- CAS还会引起ABA问题，假如有三个线程，同时操作主内存的变量A，如果线程1把主存的变量改成B，线程三又把它从b改成了a，线程二可能是和线程一一起执行的，是想从a改成b的，经过线程一和线程三个操作之后内存又变成了a，这个时候就会出现问题，虽然线程2要改的值和期望的值是一样的，但是他不符合原子性，为了解决这个问题，在此基础上追加一个版本每次通过版本号比对然后进行修改，java中提供的这样一个类叫AtomicStampedReference

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686299633342-df677698-82f8-4d12-8d93-794ad560ed1f.png)

- 自旋时间过长有很多解决方案

- - 比如说参考synchronized的自旋锁，先执行一段时间的CAS或者自旋了特定的次数，如果还有没有被释放，那就照常把线程挂起
  - 第二种是java当中的实现方式，java提供了一个类叫LongAddr。他里边有个分段锁，正常情况下只对某个值进行CAS，当并发量大了时候，比如说有1万个线程一起执行CAS，只会有一个成功的，那么如果说我给他多分几块数值，那么这一万个线程会被分摊到多个位置，同一时间就有6个线程执行成功，如果我需要这个返回值，那么只要把这多个位置的结果相加就可以返回

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686320139067-846fd650-5052-41f1-9481-586bd4eeb742.png)

# 3.ThreadLocal的内存泄露问题

首先说一下ThreadLocal的内部实现原理，ThreadLocal其实并不是真正存数据的地方，真正存数据的地方是Thread对象内部，他有一个成员变量叫ThreadLocalMap，实际上数据是存放在Thread里边，而不是ThreadLocal里边。

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686321125667-d4446ba8-ae20-43bd-b573-9615ae357f8d.png)

ThreadLocal本身不存储数据，它更像是一个工具类，是基于ThreadLocal去操作ThreadLocalMap 。ThreadLocalMap是ThreadLocal的一个内部类，ThreadLocalMap本身就是基于Entry[]实现的，因为一个线程可以绑定多个ThreadLocal，这样 一来，可能需要存储多个数据，所以采用Entry[]的形式实现。每一个现有都自己独立的ThreadLocalMap，再基于ThreadLocal对象本身作为key，对value进行存取。所以说ThreadLocal是一个工具类，它里边维护着ThreadLocalMap，同时ThreadLocal也是ThreadLocalMap当中的entry的一个key；ThreadLocalMap的key是一个弱引用，它继承了WeakReference这个类，实现了弱引用，弱引用的特点是，即便有弱引用，在GC时，也必须被回收。这里是为了在ThreadLocal对象失去引用后，如果key的引用是强引用，会导致 ThreadLocal对象无法被回收；



![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686538338438-69a4c314-d1b5-41e2-91f9-7b540c3e2f43.png)

ThreadLocal的内存泄露分为key内存泄露和value内存泄露

- 因为ThreadLocalMap本身是线程维护的一个对象，ThreadLocal引用放在jvm的堆内存当中，如果ThreadLocal在堆内存的引用已经丢失了，但是线程还在，线程指向ThreadLocalMap，而ThreadLocalMap的key指向ThreadLocal，如果此时是强引用，那么jvm无法进行gc回收，所以引用对象换成弱引用，java当中通过继承WeakReference的方式解决
- ThreadLocalMap对象本身是通过key去寻找value，如果他的key已经被gc回收掉了，那么就无法通过key找到value，从而造成内存泄露；只需要在使用完毕ThreadLocal对象之后，及时的调用remove方法，移除Entry即可(一般出现在线程池中)

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686539101469-d2fa0011-7a89-4b59-b3d4-14faa528a6de.png)

# 4.java中锁的分类

## 4.1.可重入锁、不可重入锁

Java中提供的synchronized，ReentrantLock，ReentrantReadWriteLock都是可重入锁。 

**重入:**当某一个线程拿了一次a锁之后再次获取A锁是可以直接拿到的。像java中提供的synchronized，ReentrantLock等，内部都有一个计数器，每次获取锁，计数器就会加一，释放锁的时候计数器就会减一，直到减为0才算释放锁。

**不可重入:**当某线程获取到A锁，在获取之后尝试再次获取A锁，无法获取到的，因为A锁被当前线程占用着，需要等待自己释放锁再获取锁。所以就造成了死锁，java当中的互斥锁大多数都是可重入的。java中的一个线程池ThreadPoolExecutor内部有个worker对象，它继承了AbstractQueueSynchronizer，就是一个不可重入锁

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686552462067-94d2b8cc-d50d-407e-b8ab-f34706bb4f58.png)

## 4.2.乐观锁、悲观锁

Java中提供的synchronized，ReentrantLock，ReentrantReadWriteLock都是悲观锁。

Java中提供的CAS操作，就是乐观锁的一种实现。

**悲观锁:**获取不到锁资源时，会将当前线程挂起(进入BLOCKED、WAITING)，线程挂起会涉及到用户态和内核的态的切换，而这种切换是比较消耗资源的。

- **用户态:**JVM可以自行执行的指令，不需要借助操作系统执行。 
- **内核态:**JVM不可以自行执行，需要操作系统才可以执行。

**乐观锁:**获取不到锁资源，开始自旋，再次让CPU调度，重新尝试获取锁资源。 

Atomic原子性类中，就是基于CAS乐观锁实现的。

乐观锁和悲观锁的区别就在于，线程是否挂起，是否涉及到了用户态到内核态的切换

## 4.3.公平锁、非公平锁

java中的synchronized是非公平锁

Java中提供的ReentrantLock，ReentrantReadWriteLock可以实现公平锁和非公平锁

**公平锁：**线程A获取到了锁资源，线程B没有拿到，线程B去排队，线程C来了，锁被A持有，同时线程B在排队。直接排到B的后面，等待B拿到锁资源或者是B取消后，才可以尝试去竞争锁资源。

**非公平锁:**线程A获取到了锁资源，线程B没有拿到，线程B去排队，线程C来了，先尝试竞争一波

- 拿到锁资源:开心，插队成功。
- 没有拿到锁资源:依然要排到B的后面，等待B拿到锁资源或者是B取消后，才可以尝试去竞争锁资源。

这个抢占锁资源的情况只发生在线程A刚释放锁或者线程B刚释放锁的时候

## 4.4.互斥锁、共享锁

Java中提供的synchronized、ReentrantLock是互斥锁。 

Java中提供的ReentrantReadWriteLock，有互斥锁也有共享锁。 

**互斥锁:**同一时间点，只会有一个线程持有者当前互斥锁。 

**共享锁:**同一时间点，当前共享锁可以被多个线程同时持有。一般配合读写锁进行使用，读锁和写锁是互斥的，但是读读操作是共享的。

# 5.synchronized的实现原理

synchronized一般同步方法和同步代码块。 

如果使用同步方法

- **static:**此时使用的是当前类.class作为锁(类锁) 
- **非static:**此时使用的是当前对象做为锁(对象锁)

synchronized它本身是基于对象去实现的，无论你用的是类锁还是对象锁，它都会在你的堆内存中有一片空间，去存储的一些数据。就比如new Object();他会首先在堆内存中开辟一块空间，主要存储三块数据，对象头、实例数据和对象填充；对象头里边包含MarkWord和classPoint，对象的锁信息都是存储在MarkWord中的

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686554272753-3d2353b0-358d-4930-a4e2-fad0e11f876a.png)

在hosport虚拟机中的实现里面，有锁的状态，以及当前这个锁是被哪个线程持有；

- 无锁状态，无锁状态下markword里面还会去存储一些哈希code，分代年龄，同时他会用低三位标记我当前锁的状态。001代表无锁。

- - 当前对象没有作为锁存在。

- 那么如果说当前锁已经被某一个线程持有了，并且是一个偏向锁的状态；它会用54个比特位去指向当前线程。同时他的低三位会变成101，来表示当前锁是一个偏向锁。

- - 如果当前锁资源，只有一个线程在频繁的获取和释放，那么这个线程过来，只需要判断，当前指向的线程是否是当前线程。

- - - 如果是，直接拿着锁资源走。
    - 如果当前线程不是我，基于CAS的方式，尝试将偏向锁指向当前线程。如果获取不到，触发锁升级，升级为轻量级锁。(偏向锁状态出现了锁竞争的情况)

- 当前锁升级到了轻量级锁的时候，他的末尾会采用两个锁标志位00。这个时候代表的是它是一个轻量级锁，他会指向指定的线程栈中Lock Record的指针。他会把markword里边的信息压入线程栈中，存入Lock Record。

- - 轻量级锁会采用自旋锁的方式去频繁的以CAS的形式获取锁资源(采用的是自适应自旋锁) 如果成功获取到，拿着锁资源走
  - 如果自旋了一定次数，没拿到锁资源，锁升级。

- 锁再次升级到重量级锁，那它的末尾两个比特位是一零，代表的是重量级锁。重量级锁直接指向的是c++当中的实现，就是markwordhttps://hg.openjdk.org/jdk8u/jdk8u/hotspot/file/69087d08d473/src/share/vm/runtime/objectMonitor.hpp，他里边就记录竞争线程锁的个数、锁被谁持有

- - **重量级锁:**就是最传统的synchronized方式，拿不到锁资源，就挂起当前线程。(用户态&内 核态)

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686554290426-e7e70753-496d-474e-8e8c-c3bfec4b67c6.png)

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686559224001-f7b2af3f-76da-4f58-9e9e-af9dc0de0194.png)

# 6.什么是AQS

AQS就是AbstractQueuedSynchronizer抽象类，AQS其实就是JUC包下的一个基类，JUC下的很多内容都是基于AQS实现了部分功能，比如ReentrantLock，ThreadPoolExecutor，阻塞队列， CountDownLatch，Semaphore，CyclicBarrier等等都是基于AQS实现。

首先AQS中提供了一个由volatile修饰，并且采用CAS方式修改的int类型的state变量。 ReentrantLock中使用了该state变量，来标记当前的互斥锁有没有线程持有，如果没有被持有，那就是0，否则就大于0。ThreadPoolExecutor的worker线程基于state去实现了一个锁的概念，还有CountDownLatch基于整个state作为它的一个计数器。比如在初始化的时候对CountDownLatch的state进行一个初始化，然后之后每次执行countdown方法的时候都会对staet做一个减一操作。

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686559734157-47785cc3-0346-40d5-badc-a749563dee9d.png)



其次AQS中维护了一个双向链表，有head，有tail，还包含一些线程的信息，并且每个节点都是Node对象。

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686560510664-f4db950b-2ac8-4e85-b4bf-220c978c61b2.png)

当一个线程需要获取锁资源，发现锁被占用的时候，就会把这个线程放入AQS的双向链表中，他会把这个线程封装成一个node，并且调用addWaite方法将线程加入AQS的双向链表中

除此之外还有一个conditionObject对象，比如某个线程持有锁执行await方法的时候，那么线程就会挂起。这种挂起的操作如果在synchronized里边，他会基于你的EntryList把你线程丢到waitSet的一个等待池里边，等到线程被唤醒的时候，再放回EntryList这样的双向链表中。在AQS里边如果线程调用await方法之后那么会把该线程放入ConditionObject的双向链表中，只有再次唤醒才会放入AQS的双向链表，去竞争资源。

![img](https://cdn.nlark.com/yuque/0/2023/png/22054115/1686561112460-e67c86e9-2234-4563-ad19-f2046720466c.png)

# 7.java中的四种引用类型

Java中的使用引用类型分别是**强，软，弱，虚。**

- 强引用是平常开发用的最多的，比如说当咱们去new一个对象的时候，那么new出来的这样一个对象就是一个强引用。如果一个对象是强引用的话，那么它始终处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之一。
- 对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中，作为缓存使用。java当中是通过SoftReference类去实现软引用的
- 然后就是弱引用，它的生命周期比软引用还要短很多，因为弱引用对象有个特点，只要执行了一次垃圾回收这种操作，不管jvm内存是否空间充足，都会把弱引用对象给它干掉。可以解决内存泄漏问题， ThreadLocal就是基于弱引用来解决它value的内存泄漏问题。
- 最后是虚引用，它不能单独使用，必须和引用队列联合使用，因为你new出来坠毁是看不到他的。虚引用的主要作用是跟踪对象被垃圾回收的状态。

# 8.工作线程是不是设置的越大越好？调用sleep方法是不是一直占有cpu？单核CPU设置多线程是否有意义？线程池的线程数量设置多少合适？

不是，比如我本来有10个线程，工作是稳定的，调度算法也调度的过来，突然之间改成了10w个线程。因为操作系统要保证每个线程都有执行的机会，cpu会频繁的切换线程，时间都会浪费在cpu调度。调用sleep方法是不占用cpu的，对于sleep来说，占用cpu主要是时间片切换消耗的时间。

线程调度分为两种。第一个是线程过来的时间，比如前端调用网络请求发送到后端，这个时候是不占用cpu的，第二个是后端业务处理，这个占用cpu。所以单核线程的话也是可以设置多线程的，最优解就是线程没占用cpu的时候，另外一个线程占用

线程池设置的大小和这个网络请求时间以及cpu占用时间的比例有关系，比如是1比1，那单核线程的线程池大小可以设置成2，这个时间统计有很多方法比如profile或者直接留日志统计。

# 9.什么是超线程？

一颗cpu可以包含好多个核，正常情况下，每个核对应一个线程，比如有两个核，那就对应两个线程。就好比两个服务员可以同时服务两个顾客一样。正常情况下一个cpu里边包含一个ALU和一个指令寄存器组，超线程情况下一个ALU对应多个指令寄存器组。这样的话，他每个指令寄存器组都可以把数据拿到，在进行cpu切换的时候，就不需要从外界去获取数据，可以直接在核的内部进行获取，效率很高
